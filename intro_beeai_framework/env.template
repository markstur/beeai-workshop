# Set your OpenAI API key here (for OpenAI) or just use placeholder for ollama
OPENAI_API_KEY=placeholder

# If using ollama to run models locally:
PROVIDER_ID=ollama
MODEL_ID=granite3.3
OLLAMA_BASE_URL=http://localhost:11434/v1

# BeeAI logging
# Use WARNING for less logging, DEBUG for more.
BEEAI_LOG_LEVEL=INFO

